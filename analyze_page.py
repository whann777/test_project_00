import streamlit as st
import os
import pandas as pd
from tta_core import TTADocumentAnalyzer, TTAReconciliationSystem, ALLOWANCE_CATEGORIES
import json
from datetime import datetime

def show():
    st.markdown("# üîç For Analyze")
    st.markdown("### ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Agreement Contract")
    
    # Back button
    if st.button("‚Üê ‡∏Å‡∏•‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å"):
        st.session_state.mode = None
        st.rerun()
    
    st.markdown("---")
    
    # Tabs
    tab1, tab2, tab3 = st.tabs(["üìÑ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£", "üßÆ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì & ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö", "üìä ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"])
    
    # ================== TAB 1: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ==================
    with tab1:
        st.markdown("### üìÑ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ PDF")
        
        # API Key input
        api_key = st.text_input(
            "üîë Google Gemini API Key",
            type="password",
            help="‡πÉ‡∏™‡πà API Key ‡∏à‡∏≤‡∏Å Google AI Studio"
        )
        
        if not api_key:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà API Key ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
            st.info("""
            **‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ API Key:**
            1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà https://aistudio.google.com/app/apikey
            2. ‡∏™‡∏£‡πâ‡∏≤‡∏á API Key ‡πÉ‡∏´‡∏°‡πà
            3. Copy ‡∏°‡∏≤‡πÉ‡∏™‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô
            """)
            return
        
        # File uploader
        uploaded_files = st.file_uploader(
            "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå PDF (‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå)",
            type=['pdf'],
            accept_multiple_files=True,
            help="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Agreement Contract ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"
        )
        
        if uploaded_files:
            st.success(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(uploaded_files)} ‡πÑ‡∏ü‡∏•‡πå")
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
            with st.expander("üìã ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î"):
                for idx, file in enumerate(uploaded_files, 1):
                    st.write(f"{idx}. {file.name} ({file.size / 1024:.2f} KB)")
            
            # ‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
            if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå", type="primary", use_container_width=True):
                analyze_documents(api_key, uploaded_files)
    
    # ================== TAB 2: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì & ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö ==================
    with tab2:
        st.markdown("### üßÆ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ú‡∏• analysis ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
        if 'analysis_results' not in st.session_state or not st.session_state.analysis_results:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏ô Tab ‡πÅ‡∏£‡∏Å‡∏Å‡πà‡∏≠‡∏ô")
            return
        
        st.success(f"‚úÖ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: {len(st.session_state.analysis_results)} ‡πÑ‡∏ü‡∏•‡πå")
        
        # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î AP ‡πÅ‡∏•‡∏∞ AR files
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üì• ‡πÑ‡∏ü‡∏•‡πå‡∏¢‡∏≠‡∏î‡∏ã‡∏∑‡πâ‡∏≠ (AP)")
            ap_file = st.file_uploader(
                "Account Payable CSV",
                type=['csv'],
                key='ap_file',
                help="‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≠‡∏î‡∏ã‡∏∑‡πâ‡∏≠‡∏à‡∏≤‡∏Å Supplier"
            )
        
        with col2:
            st.markdown("#### üì• ‡πÑ‡∏ü‡∏•‡πå‡∏¢‡∏≠‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏Å‡πá‡∏ö (AR)")
            ar_file = st.file_uploader(
                "Account Receivable CSV",
                type=['csv'],
                key='ar_file',
                help="‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≠‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡∏à‡∏£‡∏¥‡∏á"
            )
        
        # ‡∏õ‡∏∏‡πà‡∏°‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
        if ap_file:
            st.info("üí° ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå AR (‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏¢‡∏≠‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏Å‡πá‡∏ö)")
            
            if st.button("üßÆ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö", type="primary", use_container_width=True):
                calculate_and_reconcile(ap_file, ar_file)
        else:
            st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå AP ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì")
    
    # ================== TAB 3: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ==================
    with tab3:
        st.markdown("### üìä ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô")
        
        if 'reconciliation_system' not in st.session_state:
            st.info("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÉ‡∏ô Tab ‡∏ó‡∏µ‡πà 2 ‡∏Å‡πà‡∏≠‡∏ô")
            return
        
        recon = st.session_state.reconciliation_system
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        if recon.calculated_allowances is not None:
            display_results(recon)
        else:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì")


def analyze_documents(api_key: str, uploaded_files):
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ PDF"""
    analyzer = TTADocumentAnalyzer(api_key)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå temp
    temp_dir = "/tmp/tta_docs"
    os.makedirs(temp_dir, exist_ok=True)
    
    # Progress bar
    progress_bar = st.progress(0)
    status_text = st.empty()
    results_container = st.container()
    
    analysis_results = []
    
    for idx, uploaded_file in enumerate(uploaded_files):
        # Save file
        pdf_path = os.path.join(temp_dir, uploaded_file.name)
        with open(pdf_path, 'wb') as f:
            f.write(uploaded_file.getvalue())
        
        # Update progress
        progress = (idx + 1) / len(uploaded_files)
        progress_bar.progress(progress)
        status_text.text(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå {idx + 1}/{len(uploaded_files)}: {uploaded_file.name}")
        
        # Analyze
        with results_container:
            with st.expander(f"üìÑ {uploaded_file.name}", expanded=True):
                result = analyzer.analyze_document(pdf_path)
                
                if result:
                    st.success("‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Vendor Code", result.get('vendor_code', 'N/A'))
                    with col2:
                        st.metric("Division", result.get('Division_name', 'N/A'))
                    with col3:
                        st.metric("Allowances", len(result.get('allowances', [])))
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î allowances
                    if result.get('allowances'):
                        st.markdown("**Allowances:**")
                        df_allowances = pd.DataFrame(result['allowances'])
                        st.dataframe(df_allowances, use_container_width=True)
                    
                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô JSON
                    json_filename = uploaded_file.name.replace('.pdf', '_summary.json')
                    json_path = os.path.join(temp_dir, json_filename)
                    analyzer.save_summary(result, json_path)
                    
                    analysis_results.append({
                        'filename': uploaded_file.name,
                        'result': result,
                        'json_path': json_path
                    })
                else:
                    st.error("‚ùå ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
    
    progress_bar.progress(1.0)
    status_text.text("‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
    
    # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô session state
    st.session_state.analysis_results = analysis_results
    st.session_state.temp_dir = temp_dir
    
    # ‡∏õ‡∏∏‡πà‡∏° Download JSON
    if analysis_results:
        st.markdown("---")
        st.markdown("### üíæ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå JSON")
        
        cols = st.columns(len(analysis_results))
        for idx, result_info in enumerate(analysis_results):
            with cols[idx]:
                with open(result_info['json_path'], 'r', encoding='utf-8') as f:
                    json_data = f.read()
                
                st.download_button(
                    label=f"üì• {result_info['filename'].replace('.pdf', '.json')}",
                    data=json_data,
                    file_name=result_info['filename'].replace('.pdf', '_summary.json'),
                    mime='application/json',
                    use_container_width=True
                )


def calculate_and_reconcile(ap_file, ar_file=None):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á system
    temp_dir = st.session_state.get('temp_dir', '/tmp/tta_docs')
    recon = TTAReconciliationSystem(base_folder=temp_dir)
    
    progress_text = st.empty()
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå AP
    progress_text.text("üì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• AP...")
    ap_path = os.path.join(temp_dir, ap_file.name)
    with open(ap_path, 'wb') as f:
        f.write(ap_file.getvalue())
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå AR (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    if ar_file:
        progress_text.text("üì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• AR...")
        ar_path = os.path.join(temp_dir, ar_file.name)
        with open(ar_path, 'wb') as f:
            f.write(ar_file.getvalue())
    
    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
        # Load TTA
        progress_text.text("üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• TTA...")
        json_files = [r['json_path'] for r in st.session_state.analysis_results]
        tta_loaded = recon.load_tta_summaries(json_files)
        
        # Load AP
        progress_text.text("üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• AP...")
        ap_loaded = recon.load_ap_data(ap_path)
        
        # Load AR
        ar_loaded = False
        if ar_file:
            progress_text.text("üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• AR...")
            ar_loaded = recon.load_ar_data(ar_path)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
        if tta_loaded and ap_loaded:
            progress_text.text("üßÆ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Allowances...")
            calculated = recon.calculate_allowances()
            
            # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö AR
            if ar_loaded:
                progress_text.text("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö AR...")
                reconciliation = recon.reconcile_with_ar()
    
    progress_text.text("‚úÖ ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!")
    
    # ‡πÄ‡∏Å‡πá‡∏ö system ‡πÉ‡∏ô session state
    st.session_state.reconciliation_system = recon
    
    st.success("‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Tab '‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô")
    st.balloons()


def display_results(recon: TTAReconciliationSystem):
    """‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"""
    
    # Summary metrics
    st.markdown("### üìà ‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°")
    
    if recon.reconciliation_result is not None:
        summary = recon.generate_summary_report()
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Vendor",
                len(summary)
            )
        
        with col2:
            st.metric(
                "‡∏Ñ‡∏ß‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î",
                f"‡∏ø{summary['should_collect'].sum():,.2f}"
            )
        
        with col3:
            st.metric(
                "‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î",
                f"‡∏ø{summary['actually_collected'].sum():,.2f}"
            )
        
        with col4:
            diff = summary['difference'].sum()
            st.metric(
                "‡∏™‡πà‡∏ß‡∏ô‡∏ï‡πà‡∏≤‡∏á",
                f"‡∏ø{diff:,.2f}",
                delta=f"{diff:,.2f}",
                delta_color="inverse" if diff < 0 else "normal"
            )
        
        st.markdown("---")
        
        # Summary table
        st.markdown("### üìä ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏° Vendor")
        st.dataframe(
            summary.style.format({
                'should_collect': '‡∏ø{:,.2f}',
                'actually_collected': '‡∏ø{:,.2f}',
                'difference': '‡∏ø{:,.2f}',
                'variance_pct': '{:.2f}%'
            }),
            use_container_width=True
        )
        
        # Detailed view
        st.markdown("---")
        st.markdown("### üîç ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà")
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Vendor
        vendors = recon.reconciliation_result['vendor_code'].unique()
        selected_vendor = st.selectbox(
            "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Vendor",
            options=['‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î'] + list(vendors)
        )
        
        # Filter data
        if selected_vendor == '‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î':
            filtered_data = recon.reconciliation_result
        else:
            filtered_data = recon.reconciliation_result[
                recon.reconciliation_result['vendor_code'] == selected_vendor
            ]
        
        st.dataframe(
            filtered_data.style.format({
                'should_collect': '‡∏ø{:,.2f}',
                'actually_collected': '‡∏ø{:,.2f}',
                'difference': '‡∏ø{:,.2f}',
                'variance_pct': '{:.2f}%'
            }),
            use_container_width=True
        )
    
    else:
        # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ calculated allowances
        st.markdown("### üí∞ ‡∏¢‡∏≠‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏Å‡πá‡∏ö")
        st.info("‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• AR - ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏¢‡∏≠‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ")
        
        st.dataframe(
            recon.calculated_allowances.style.format({
                'total_purchase': '‡∏ø{:,.2f}',
                'should_collect': '‡∏ø{:,.2f}',
                'rate_percent': '{:.2f}%',
                'fix_amount': '‡∏ø{:,.2f}'
            }),
            use_container_width=True
        )
    
    # Export buttons
    st.markdown("---")
    st.markdown("### üíæ Export ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üì• Export ‡πÄ‡∏õ‡πá‡∏ô Excel", type="primary", use_container_width=True):
            output_file = recon.export_results()
            if output_file:
                with open(output_file, 'rb') as f:
                    st.download_button(
                        label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Excel",
                        data=f,
                        file_name=os.path.basename(output_file),
                        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                        use_container_width=True
                    )
    
    with col2:
        if recon.reconciliation_result is not None:
            csv_data = recon.reconciliation_result.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="üì• Export ‡πÄ‡∏õ‡πá‡∏ô CSV",
                data=csv_data,
                file_name=f"TTA_Reconciliation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime='text/csv',
                use_container_width=True
            )
